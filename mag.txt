1. Wstęp
2. Wprowadzenie
3. Po co są testy jednostkowe
4. 
5. Historia biblioteki boost unittest
6. Historia biblioteki google test (gtest)
7. OPis przeprowadzony badań
Definicja testu w badanych bibliotekach
Grupowanie testów
Podstawowe metody weryfikacji - asercje
TODO Porównywanie liczb zmiennoprzecinkowych
TODO Obsługa wyjątków
Sposoby przygotowania środowiska przed rozpoczęciem testu
Testy parametryzowane
Testy z użyciem szablonów
Sposób prezentacji wyników testów
Formatowanie komunikatów o błędach
Sterowanie wykonywaniem testów
Ustawienia formatu wyjściowego uruchomionych testów
Zebranie i analiza wyników badań




W jakim kierunku można rozwinąć pracę
Ocena krytyczna pracy

Przyjęty sposób prowadzenia badań

Podczas realizacji badań przyjęto kilka założeń, które oprócz usystematyzowania prac starają się uczynić wyniki jak najbardziej czytelne.
Projekt został stworzony przy pomocy systemu budowania CMake [TODO link].
Każdy z zareprezentowanych testów znajduję się w osobnym katalogu, wewnątrz którego znajdują się katalogi z kodem źródłowym przykładowych programów (nazwany src), jeśli taki program wymagany był do użycia w teście oraz katalog z plikami testów (nazwany test). Oprócz tego znajduję się tam plik CMakeLists.txt, któy zawiera zbiór instukcji dla systemu budowania CMake w celu poprawnego wygnerowania projektu - w przypadku tej pracy pliku solucji dla programu Microsoft Visual Studio C++ Community 2015.
W głównym katalogu projektu znajdują się także foldery include - zawierający pliki nagłówkowe badanych bibliotek, oraz lib - katalog zawierający wcześniej skompilowane biblioteki dynamiczne badanych srodowisk do testów jednostkowych.
W momencie budowania tworzony jest katalog bin, w którym umieszczane są już skompilowane pliki wykonywalne testów służące do ich uruchomienia oraz pliki przykładowych programów o ile takie zostały dołączone do prezentowanych przykładów.

Opis przeprowadzonych badań

W celu pozyskania wiedzy potrzebnej do przeprowadzenie analizy porównawczej wykonane zostały testy jednostkowe, których zadaniem było ukazanie podobieństw oraz różnic obu bibliotek. Wyniki pozyskane w ten sposób zostały uzupełnione poprzez studia literaturowe bazujące na dokumentacji dostępnej dla użytkowników bibliotek.
W swoich badaniach przyjąłem założenie o nie uzupełnianiu pozyskanej z dokumentacji wiedzy analizując kod źrółowy obu frameworków, bo mogło by zakłócić idee, z którymi oba środowiska były dostarczane. W obu przypadkach językiem użytym do stworzenia bibliotek był język C++, więc teoretycznie możliwości obu bibliotek powinny być porównywalne.
W czasie realizacji badań zostały przygotowane 37 testów (21 testów z biblioteki Boost oraz 16 testów z biblioteki Google), któe bazowały na wiedzy pozyskanej ze studiowanej dokumentacji.
Badania zostały przeprowadzone na bibliotekach skompilowanych do plików bibliotek ładowanych dymamicznie (DLL TODO[X]). Testy zostały napisane, skompilowane oraz uruchomione w środowisku Microsoft Windows 7 przy użyciu środowiska Microsoft Visual Studio C++ w wersji Community 2015 wraz z dostarczonym z nim kompilatorem w wersji TODO[X].

Definicja Testu w badanych bibliotekach.

Obie biblioteki do definicji podstawowej jednostki w testach jednostkowych - przypadku testowego (z ang. test case, dalej TC) oferują podobne rozwiązania. Jednocześnie w obu przypdkach zalecane jest użycie makr w języku C++ do zdefiniowania TCu, co znacznie uławia pisanie testów oraz zwiększa produktywność podczas otestowywania całych modułów.
Dodatkowym aspektem, który przemawia za użyciem makr jest łatwość rejestracji testów w "test runnerze", który odpowiada za uruchomienie testów.

Definicja przypadku testego w bibliotece Boost unittest

Automatyczna generacja wraz z rejestracją przpadku testowego w bibliotece Boost unittest wygląda następująco:

TODO KOD

Boost test pozwala na definiowanie testów bez przypisywania ich do grup testów (z ang. test suite). Do automatycznego wygenerowania TC służy makro BOOST_AUTO_TEST_CASE(nazwa){}

Definicja przypadku testego w bibliotece Google Test

Podobnie jak w przypadku biblioteki omawianej powyżej rejestracja TC w bibliotece realizowana jest przy pomocy prostego makra. 
Dodatkowo w poniższym przykładzie zobrazowany został sposób odpalenia wszyskich testów z funkcji wejściowej programu - funkcji main. Z tego sposobu uruchamiania testów można zrezygnować w systuacji kiedy zamianst linkować program z wcześniej wygegenrowaną biblioteką dynamiczną gtest.dll zlinkujemy program z biblioteką statyczną gtest_main.lib.

Automatyczna generacja wraz z rejestracją przpadku testowego w bibliotece Google test wygląda następująco:

TODO KOD

Grupowanie testów

W przypadku rozbudowanych programów posiadających setki testów powstaje potrzeba lepszego zarządzania nimi. Pierwszą z czynności, które przynoszą większe usystematyzowanie testów jest ich zgrupowanie. Dzięki takiemu zabiegowi łatwiej jest określić programiście, do której funkcjonalności przynależy dany TC.
W testach jednostkowych grupę testów przynależących do danej funkcjonalności nosi miano już wspomnianego określenia test suite, dalej TS. 
W przypdaku biblioteki Boost unittest mamy możliwość stworzenie testu, który nie przynależy do TS, w tej sytuacji TC jest automatycznie rejestrowany (jeśli korzystamy z makra BOOST_AUTO_TEST_CASE) do głównej TS (z ang. Master Test Suite).
Biblioteka Google test wymaga, aby każdy test case przynależał to TS, dlatego makro TEST przyjmuje dwa parametry - pierwszy to nazwa TS, drugi to nazwa TC.
Dodatkowym atutem biblioteki Boost unittest jest fakt, że TS można grupować w kolejne poziomy grupy testów - inaczej mówić test suite może zawierać inny test suite, zawieranie nie jest ograniczone do jednego poziomu oraz można zawierać wiele TS w jedej TS.
Poniżej przykłady zastosowania grupowania testów w badanych bibliotekach.

Podstawowe metody weryfikacji - asercje

Podstawowym narzędziem służącym do weryfikacji poprawności działania programów w testach są asercje, czyli porównania między spodziewaną wartością działania algorytmu a wartością otrzymaną w trakcie działania programu.
Wartości możemy porównywać na różne sposobu - nie tylko sprawdzając ich równość co do wartości spodziewanej ale również pokazując zależność między wartością spodziewaną a otrzymaną. W przypdaku obu bibliotek do porównywania wartości wykorzystywane są makra.

Podstawowe metody weryfikacji - asercje w bibliotece Boost unittest

Biblioteka Boost unittest oferuje szereg asercji, które pozwalają porównywać wartości przy pomocy operatorów takich jak <=, >=, ==, <, >, !=. Oprócz tego biblioteka oferuję trzy poziomy określające priorytet asercji: WARN, CHECK oraz REQUIRE. Dla każdego z tych poziomów istnieje ten sam zestaw assercji, na przykład porównanie co do równości z wartością oczekiwaną występuje w trzech formach BOOST_WARN_EQUAL(a, b), BOOST_CHACK_EQUAL(a, b) oraz BOOST_REQUIRE_EQUAL(a, b).
Powyżse funkcje sprawdzają czy wartość a jest równa wartości b z wykorzystaniem operatora == pomiędzy typami a oraz b - oznacza to, że można zdefiniować własny operator porównania i wykorzystywać go z biblioteką Boost unittest. 
Wynik porównania - czyli zwrócona wartość logiczna z wyrażenia a == b, interpretowany jest róźnie dla każdego z makr. Makro poziomu REQUIRE w momencie niepowdzenia porównania (a jest różne od b) powoduje wyświetlenie błędu oraz natychmiastowe przerwanie obecnego TC oraz jeśli to możliwe przejście do następnego TC.
Makro poziomu CHECK powoduję wyświetlenie wiadomości w momencie niepowodzenia, ale w odróżnieniu od makra REQUIRE pozwala kontynuować wykonywanie obecnego TC, ale TC zostaje uznany za zakończony z niepowodzeniem.
Makro poziomu WARN służy wyłącznie do wypisania wiadomości o niepowodzeniu, TC nie jest uznany za zakończony niepowodzeniem - makra tego poziomu służą tylko w celu weryfikacji danych, która nie wpływa na ogólny wynik testów.

TODO tabela z assercjami

W powyższych tabeli oprócz wspomnianych asercji korzystających z operatorów porównania możemy skorzystać z dodatkowych asercji: BOOST_<LEVEL>, BOOST_<LEVEL>_BITEWISE_EQUAL, BOOST_<LEVEL>_CLOSE, BOOST_<LEVEL>_CLOSE_FRICTION, BOOST_<LEVEL>_EQUAL_COLLECTIONS, BOOST_<LEVEL>_EXCEPTION, BOOST_<LEVEL>_MESSAGE, BOOST_<LEVEL>_NO_THROW, BOOST_<LEVEL>_THROW, BOOST_<LEVEL>_PREDICATE, gdzie <LEVEL> może przyjmować jedną z trzech opcji: REQUIRE, CHECK, WARN
BOOST_<LEVEL>(a) sprawdza czy wyrażenie w a jest prawdziwe czy też nie, jest to dość przydatne makro, ponieważ w miejsce a możemy wpisać dowolne wyrażenie, które będzie sprowadzone do wartości logicznej.
Jednym z wyspecjalizowanych makr jest BOOST_<LEVEL>_BITEWISE_EQUAL(a, b), jest on szczególnie przydatny dla programistów pracujących na przykład na zbiorze flag. W momencie stwierdzenia nierówności między a i b sprawdza on na których pozycjach występuję przekłamanie. Dzięki temu oszczędza to czasu dla programisty, który w szybki sposób może zweryfikować za co był odpwoiedzialny dany bit.
BOOST_<LEVEL>_EQUAL_COLLECTION(ab, ae, bb, be) jest odpowiednikiem BOOST_<LEVEL>_EQUAL, który można wywołać na kolekcjach danych jak kontenery w języcku C++11, które posiadają możliwość przeglądu elementów przy pomocy iteratorów albo na tablicach w stylu języka C. Parametry jakie przyjmuje to początek oraz koniec pierwszej kolecji oraz początek i koniec drugiej kolekcji. Poprzez koniec kolekcji rozumiany jest wskaźnik na element tuż za ostatnim istniejącym elementem kolecji.
Makro BOOST_<LEVEL>_MESSAGE(a, m) jest odpowiednikiem makra BOOST_<LEVEL> - sprawdza czy wyrażenie zawarte w a jest prawdą. Drugi z parametrów, który przyjmuje jest to wskaźnik na niestandardową wiadomość, która będzie wyświetlona w momencie niepowodzenia.
BOOST_<LEVEL>_PREDICATE(pred, (a)(b)) pozwala na zawołanie funkcji - predykatu, która zwróci wartość logiczną na podstawie przekazanych do niej wartości. Jest to jedno z makr, które posiada nietypową konstrukcję, ponieważ parametry przekazywane do predykatu należy podać w okrągłych nawiasach jako drugi parametr.
Pozostałe z operatorów będą omówione w następnych rodziałach tej pracy TODO.

Podstawowe metody weryfikacji - asercje w bibliotece Boost unittest

Podobnie jak w bibliotece Boost unittest w przypdaku biblioteki Google test mamy do dyspozcyji szereg asercji oparych na operatorach porówania. W przypdaku biblioteki Google test występują dwa poziomy priorytetów asercji - ASSERT oraz EXPECT. Pierwszy z nich odpowiada asercją REQUIRE, drugi asercją CHECK, czyli asercje poziomu ASSERT w momencie niepowodzenia zatrzymują dany TC oraz wypisują napotkany błąd, natomiast EXPECT powoduje tylko wypisanie przyczyny błędu.
Poniżej przedstawiono wykaz dostępnych assercji dla biblioteki Google test.

TODO tabelka z asercjami

Dodatkowe asercje występujące w tej bibliotece to <LEVEL>_STREQ, <LEVEL>_STRNE, <LEVEL>_STRCASEEQ, <LEVEL>_STRCASENE, <LEVEL>_THROW, <LEVEL>_NO_THROW, <LEVEL>_ANY_THROW, <LEVEL>_FLOAT_EQ, <LEVEL>_DOUBLE_EQ, <LEVEL>_NEAR.
<LEVEL>_STREQ oraz <LEVEL>_STRNE służą do porównywania ciągów znakowych (z ang. string). Pierwszy z nich sprawdza czy podane ciągi są takie same, drugi natomiast sprawdza czy są one od siebie różne. Opisywane asercje przyjmują dwa parametry - ciąg sprawdzany oraz ciąg spodziewany, są one wrażliwe na wielkości liter w badanych ciągach. Jeśli wielkość liter na nie mieć znaczenia podczas wykonywania porównania należy skorzystać z operatorów 
<LEVEL>_STRCASEEQ, <LEVEL>_STRCASENE. Podobnie jak <LEVEL>_STREQ oraz <LEVEL>_STRNE asercje <LEVEL>_STRCASEEQ, <LEVEL>_STRCASENE przyjmują dwa parametry.
W bibliotece Google test do dyspozycji mamy dodatkowe makra służące tylko do zaznaczania tego, że test zakończył się powodzeniem lub też nie - są to makra SUCCEED, FAIL, ADD_FAILURE oraz ADD_FAILURE_AT.
SUCCEED jest mało przydatnym makrem, ponieważ jest to odpowiednik ASSERT_TRUE(true), a więc zawsze generuje pozytywny wynik. Ważne jest to, że makro SUCCEED nie powoduję, że cały TC jest oznaczany jako zakończony sukcesem.
Makra FAIL, ADD_FAILURE oraz ADD_FAILURE_AT są już bardziej przydatne ze względu na to, że wpływają na wynik TC. FAIL generuję fatalny błąd powodujący przerwanie przetwarzania obecnego testu natomiast ADD_FAILURE oraz ADD_FAILURE_AT powodują zaraportowanie błędu, ale pozwalają na dokończenie przetwarzania obecnego TC.
SUCCEED, FAIL oraz ADD_FAILURE nie przyjmują żadnych parametrów, natomiast ADD_FAILURE_AT przyjmuje dwa parametry - nazwę pliku oraz numer lini, w której wystąpił błąd.
FAIL, ADD_FAILURE oraz ADD_FAILURE_AT przydają się w sytuacjach kiedy chcemy sprawdzić czy testowana funkcjonalność nie osiągnie nigdy miejsca w kodzie gdzie jedno z przytoczonych makr występuje. Najlepszym przykładem zastosowania tych makr jest zastosowane ich w funkcji zwrotnej (z ang. callback), którą może przyjmować jedna z testowanych metod. W przytoczonym przykładzie możemy sprawdzić czy zdefiniowana przez nas funckja nie została nigdy zawoła - jej zawołanie spowoduję wygenerowanie błędu.
Makra <LEVEL>_THROW, <LEVEL>_NO_THROW, <LEVEL>_ANY_THROW, <LEVEL>_FLOAT_EQ, <LEVEL>_DOUBLE_EQ, <LEVEL>_NEAR zostaną omówione w dalszej części pracy. TODO

Sposoby przygotowania środowiska przed rozpoczęciem testu

Podczas pisania testów jednostkowych niekiedy aby przetestować jedną funkcjonalność potrzebujemy 







